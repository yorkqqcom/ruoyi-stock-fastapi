import importlib
import json
from asyncio import iscoroutinefunction
from collections.abc import Callable
from datetime import datetime, timedelta
from typing import Any

from apscheduler.events import EVENT_ALL, SchedulerEvent
from apscheduler.executors.asyncio import AsyncIOExecutor
from apscheduler.executors.pool import ProcessPoolExecutor
from apscheduler.job import Job
from apscheduler.jobstores.memory import MemoryJobStore
from apscheduler.jobstores.redis import RedisJobStore
from apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.combining import OrTrigger
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.date import DateTrigger
from sqlalchemy.engine import create_engine
from sqlalchemy.orm import sessionmaker

import module_task  # noqa: F401
from config.database import AsyncSessionLocal, quote_plus
from config.env import DataBaseConfig, RedisConfig
from module_admin.dao.job_dao import JobDao
from module_admin.entity.vo.job_vo import JobLogModel, JobModel
from module_admin.service.job_log_service import JobLogService
from module_tushare.dao.tushare_dao import TushareDownloadTaskDao
from module_tushare.entity.vo.tushare_vo import TushareDownloadTaskModel
from utils.common_util import CamelCaseUtil
from utils.log_util import logger


# é‡å†™Cronå®šæ—¶
class MyCronTrigger(CronTrigger):
    CRON_EXPRESSION_LENGTH_MIN = 6
    CRON_EXPRESSION_LENGTH_MAX = 7
    WEEKDAY_COUNT = 5

    @classmethod
    def from_crontab(cls, expr: str, timezone: str | None = None) -> 'MyCronTrigger':
        values = expr.split()
        if len(values) != cls.CRON_EXPRESSION_LENGTH_MIN and len(values) != cls.CRON_EXPRESSION_LENGTH_MAX:
            raise ValueError(f'Wrong number of fields; got {len(values)}, expected 6 or 7')

        second = values[0]
        minute = values[1]
        hour = values[2]
        
        # è§£ææ—¥æœŸå­—æ®µ
        if '?' in values[3]:
            # æ—¥æœŸå­—æ®µæ˜¯?ï¼Œè¡¨ç¤ºæŒ‰æ˜ŸæœŸæ‰§è¡Œï¼Œæ—¥æœŸè®¾ä¸ºNone
            day = None
        elif 'L' in values[5]:
            # æ˜ŸæœŸå­—æ®µåŒ…å«Lï¼Œè¡¨ç¤ºæœ€åä¸€å¤©
            day = f'last {values[5].replace("L", "")}'
        elif 'W' in values[3]:
            # æ—¥æœŸå­—æ®µåŒ…å«Wï¼Œè¡¨ç¤ºå·¥ä½œæ—¥
            day = cls.__find_recent_workday(int(values[3].split('W')[0]))
        else:
            # æ—¥æœŸå­—æ®µæ˜¯*æˆ–å…·ä½“å€¼
            day_str = values[3].replace('L', 'last')
            # APScheduleræ”¯æŒday='*'è¡¨ç¤ºæ¯å¤©
            day = day_str
        
        month = values[4]
        
        # è§£ææ˜ŸæœŸå­—æ®µ
        if '?' in values[5] or 'L' in values[5]:
            week = None
            day_of_week = None
        elif '#' in values[5]:
            # æ ¼å¼ï¼š1#2 è¡¨ç¤ºç¬¬2å‘¨çš„æ˜ŸæœŸ1
            week = int(values[5].split('#')[1])
            day_of_week = int(values[5].split('#')[0]) - 1
        else:
            # æ˜ŸæœŸå­—æ®µæ˜¯*æˆ–å…·ä½“å€¼
            if values[5] == '*':
                week = None
                day_of_week = None
            else:
                week = None
                # è§£ææ˜ŸæœŸå€¼ï¼ˆ1-7ï¼Œ1=å‘¨æ—¥ï¼Œ7=å‘¨å…­ï¼‰
                # APSchedulerä½¿ç”¨0-6ï¼Œ0=å‘¨ä¸€ï¼Œ6=å‘¨æ—¥
                # éœ€è¦è½¬æ¢ï¼šQuartzçš„1(å‘¨æ—¥) -> APSchedulerçš„6ï¼ŒQuartzçš„2-7 -> APSchedulerçš„0-5
                try:
                    week_values = [int(x) - 1 for x in values[5].split(',')]
                    # è½¬æ¢ï¼š1->6, 2->0, 3->1, 4->2, 5->3, 6->4, 7->5
                    day_of_week = [(6 if x == 0 else x - 1) for x in week_values]
                    if len(day_of_week) == 1:
                        day_of_week = day_of_week[0]
                except ValueError:
                    day_of_week = None
        
        year = values[6] if len(values) == cls.CRON_EXPRESSION_LENGTH_MAX else None
        
        # è®°å½•è§£æç»“æœç”¨äºè°ƒè¯•
        logger.debug(
            f'è§£æcronè¡¨è¾¾å¼: {expr} -> '
            f'second={second}, minute={minute}, hour={hour}, '
            f'day={day}, month={month}, week={week}, day_of_week={day_of_week}, year={year}'
        )
        
        return cls(
            second=second,
            minute=minute,
            hour=hour,
            day=day,
            month=month,
            week=week,
            day_of_week=day_of_week,
            year=year,
            timezone=timezone,
        )

    @classmethod
    def __find_recent_workday(cls, day: int) -> int:
        now = datetime.now()
        date = datetime(now.year, now.month, day)
        if date.weekday() < cls.WEEKDAY_COUNT:
            return date.day
        diff = 1
        while True:
            previous_day = date - timedelta(days=diff)
            if previous_day.weekday() < cls.WEEKDAY_COUNT:
                return previous_day.day
            diff += 1


SQLALCHEMY_DATABASE_URL = (
    f'mysql+pymysql://{DataBaseConfig.db_username}:{quote_plus(DataBaseConfig.db_password)}@'
    f'{DataBaseConfig.db_host}:{DataBaseConfig.db_port}/{DataBaseConfig.db_database}'
)
if DataBaseConfig.db_type == 'postgresql':
    SQLALCHEMY_DATABASE_URL = (
        f'postgresql+psycopg2://{DataBaseConfig.db_username}:{quote_plus(DataBaseConfig.db_password)}@'
        f'{DataBaseConfig.db_host}:{DataBaseConfig.db_port}/{DataBaseConfig.db_database}'
    )
engine = create_engine(
    SQLALCHEMY_DATABASE_URL,
    echo=DataBaseConfig.db_echo,
    max_overflow=DataBaseConfig.db_max_overflow,
    pool_size=DataBaseConfig.db_pool_size,
    pool_recycle=DataBaseConfig.db_pool_recycle,
    pool_timeout=DataBaseConfig.db_pool_timeout,
)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
redis_config = {
    'host': RedisConfig.redis_host,
    'port': RedisConfig.redis_port,
    'username': RedisConfig.redis_username,
    'password': RedisConfig.redis_password,
    'db': RedisConfig.redis_database,
}
job_stores = {
    'default': MemoryJobStore(),
    'sqlalchemy': SQLAlchemyJobStore(url=SQLALCHEMY_DATABASE_URL, engine=engine),
    'redis': RedisJobStore(**redis_config),
}
executors = {'default': AsyncIOExecutor(), 'processpool': ProcessPoolExecutor(5)}
job_defaults = {'coalesce': False, 'max_instance': 1}
scheduler = AsyncIOScheduler()
scheduler.configure(jobstores=job_stores, executors=executors, job_defaults=job_defaults)


class SchedulerUtil:
    """
    å®šæ—¶ä»»åŠ¡ç›¸å…³æ–¹æ³•
    """

    @classmethod
    async def init_system_scheduler(cls) -> None:
        """
        åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–å®šæ—¶ä»»åŠ¡

        :return:
        """
        logger.info('ğŸ” å¼€å§‹å¯åŠ¨å®šæ—¶ä»»åŠ¡...')
        
        # å¯åŠ¨è°ƒåº¦å™¨
        if not scheduler.running:
            scheduler.start()
            logger.info('âœ…ï¸ è°ƒåº¦å™¨å·²å¯åŠ¨')
        else:
            logger.warning('âš ï¸ è°ƒåº¦å™¨å·²ç»åœ¨è¿è¡Œä¸­')
        
        async with AsyncSessionLocal() as session:
            # åŠ è½½ç³»ç»Ÿå®šæ—¶ä»»åŠ¡ï¼ˆsys_jobï¼‰
            job_list = await JobDao.get_job_list_for_scheduler(session)
            logger.info(f'ğŸ“‹ ç³»ç»Ÿå®šæ—¶ä»»åŠ¡æ•°é‡: {len(job_list)}')
            for item in job_list:
                cls.remove_scheduler_job(job_id=str(item.job_id))
                cls.add_scheduler_job(item)
            
            # åŠ è½½ä¸‹è½½ä»»åŠ¡å®šæ—¶è°ƒåº¦
            logger.info('ğŸ” å¼€å§‹åŠ è½½ Tushare ä¸‹è½½ä»»åŠ¡å®šæ—¶è°ƒåº¦...')
            # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…å¾ªç¯å¯¼å…¥
            from module_tushare.service.tushare_scheduler_service import TushareSchedulerService
            
            download_tasks = await TushareDownloadTaskDao.get_tasks_for_scheduler(session)
            logger.info(f'ğŸ“‹ ä»æ•°æ®åº“æŸ¥è¯¢åˆ° {len(download_tasks)} ä¸ª Tushare ä¸‹è½½ä»»åŠ¡')
            
            success_count = 0
            fail_count = 0
            skip_count = 0
            
            for task in download_tasks:
                try:
                    task_model = TushareDownloadTaskModel(**CamelCaseUtil.transform_result(task))
                    
                    # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€å’Œcronè¡¨è¾¾å¼
                    if task_model.status != '0':
                        logger.info(
                            f'â­ï¸ è·³è¿‡ä»»åŠ¡ {task_model.task_name} (ID: {task_model.task_id}): '
                            f'ä»»åŠ¡çŠ¶æ€ä¸ºæš‚åœ (status={task_model.status})'
                        )
                        skip_count += 1
                        continue
                    
                    if not task_model.cron_expression or not task_model.cron_expression.strip():
                        logger.info(
                            f'â­ï¸ è·³è¿‡ä»»åŠ¡ {task_model.task_name} (ID: {task_model.task_id}): '
                            f'æœªé…ç½® cron è¡¨è¾¾å¼'
                        )
                        skip_count += 1
                        continue
                    
                    # æ³¨å†Œä»»åŠ¡åˆ°è°ƒåº¦å™¨
                    TushareSchedulerService.register_task_scheduler(task_model)
                    success_count += 1
                    
                except Exception as e:
                    logger.exception(
                        f'âŒ åŠ è½½ä¸‹è½½ä»»åŠ¡å®šæ—¶è°ƒåº¦å¤±è´¥: task_id={task.task_id}, '
                        f'task_name={task.task_name}, é”™è¯¯: {str(e)}'
                    )
                    fail_count += 1
            
            logger.info(
                f'âœ…ï¸ Tushare ä¸‹è½½ä»»åŠ¡å®šæ—¶è°ƒåº¦åŠ è½½å®Œæˆ: '
                f'æ€»è®¡ {len(download_tasks)} ä¸ª, '
                f'æˆåŠŸ {success_count} ä¸ª, '
                f'å¤±è´¥ {fail_count} ä¸ª, '
                f'è·³è¿‡ {skip_count} ä¸ª'
            )
            
            # éªŒè¯è°ƒåº¦å™¨ä¸­çš„ä»»åŠ¡æ•°é‡
            all_jobs = scheduler.get_jobs()
            tushare_jobs = [job for job in all_jobs if job.id and job.id.startswith('tushare_task_')]
            logger.info(f'ğŸ“Š è°ƒåº¦å™¨ä¸­å½“å‰ Tushare ä»»åŠ¡æ•°é‡: {len(tushare_jobs)}')
            
            # åˆ—å‡ºæ‰€æœ‰å·²æ³¨å†Œçš„ Tushare ä»»åŠ¡
            if tushare_jobs:
                logger.info('ğŸ“ å·²æ³¨å†Œçš„ Tushare ä»»åŠ¡åˆ—è¡¨:')
                for job in tushare_jobs:
                    next_run = job.next_run_time.strftime('%Y-%m-%d %H:%M:%S') if job.next_run_time else 'æœªå®‰æ’'
                    logger.info(f'  - {job.name} (ID: {job.id}), ä¸‹æ¬¡æ‰§è¡Œ: {next_run}')
        
        scheduler.add_listener(cls.scheduler_event_listener, EVENT_ALL)
        
        # éªŒè¯è°ƒåº¦å™¨çŠ¶æ€
        cls._verify_scheduler_status()
        
        logger.info('âœ…ï¸ ç³»ç»Ÿåˆå§‹å®šæ—¶ä»»åŠ¡åŠ è½½æˆåŠŸ')
    
    @classmethod
    def _verify_scheduler_status(cls) -> None:
        """
        éªŒè¯è°ƒåº¦å™¨çŠ¶æ€
        
        :return:
        """
        logger.info('ğŸ” éªŒè¯è°ƒåº¦å™¨çŠ¶æ€...')
        
        # æ£€æŸ¥è°ƒåº¦å™¨æ˜¯å¦è¿è¡Œ
        is_running = scheduler.running if hasattr(scheduler, 'running') else False
        logger.info(f'  è°ƒåº¦å™¨è¿è¡ŒçŠ¶æ€: {"âœ… è¿è¡Œä¸­" if is_running else "âŒ æœªè¿è¡Œ"}')
        
        # ç»Ÿè®¡æ‰€æœ‰ä»»åŠ¡
        all_jobs = scheduler.get_jobs()
        logger.info(f'  è°ƒåº¦å™¨ä¸­æ€»ä»»åŠ¡æ•°: {len(all_jobs)}')
        
        # ç»Ÿè®¡ Tushare ä»»åŠ¡
        tushare_jobs = [job for job in all_jobs if job.id and job.id.startswith('tushare_task_')]
        logger.info(f'  Tushare ä»»åŠ¡æ•°: {len(tushare_jobs)}')
        
        # ç»Ÿè®¡ç³»ç»Ÿä»»åŠ¡
        system_jobs = [job for job in all_jobs if not (job.id and job.id.startswith('tushare_task_'))]
        logger.info(f'  ç³»ç»Ÿä»»åŠ¡æ•°: {len(system_jobs)}')
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä»»åŠ¡æ²¡æœ‰ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
        jobs_without_next_run = [job for job in all_jobs if job.next_run_time is None]
        if jobs_without_next_run:
            logger.warning(f'  âš ï¸ æœ‰ {len(jobs_without_next_run)} ä¸ªä»»åŠ¡æ²¡æœ‰å®‰æ’ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´:')
            for job in jobs_without_next_run:
                logger.warning(f'    - {job.name} (ID: {job.id})')
        
        logger.info('âœ…ï¸ è°ƒåº¦å™¨çŠ¶æ€éªŒè¯å®Œæˆ')

    @classmethod
    async def close_system_scheduler(cls) -> None:
        """
        åº”ç”¨å…³é—­æ—¶å…³é—­å®šæ—¶ä»»åŠ¡

        :return:
        """
        scheduler.shutdown()
        logger.info('âœ…ï¸ å…³é—­å®šæ—¶ä»»åŠ¡æˆåŠŸ')

    @classmethod
    def _import_function(cls, func_path: str) -> Callable[..., Any]:
        """
        åŠ¨æ€å¯¼å…¥å‡½æ•°

        :param func_path: å‡½æ•°å­—ç¬¦ä¸²ï¼Œå¦‚module_task.scheduler_test.job
        :return: å¯¼å…¥çš„å‡½æ•°å¯¹è±¡
        """
        module_path, func_name = func_path.rsplit('.', 1)
        module = importlib.import_module(module_path)
        return getattr(module, func_name)

    @classmethod
    def get_scheduler_job(cls, job_id: str | int) -> Job:
        """
        æ ¹æ®ä»»åŠ¡idè·å–ä»»åŠ¡å¯¹è±¡

        :param job_id: ä»»åŠ¡id
        :return: ä»»åŠ¡å¯¹è±¡
        """
        query_job = scheduler.get_job(job_id=str(job_id))

        return query_job

    @classmethod
    def add_scheduler_job(cls, job_info: JobModel) -> None:
        """
        æ ¹æ®è¾“å…¥çš„ä»»åŠ¡å¯¹è±¡ä¿¡æ¯æ·»åŠ ä»»åŠ¡

        :param job_info: ä»»åŠ¡å¯¹è±¡ä¿¡æ¯
        :return:
        """
        job_func = cls._import_function(job_info.invoke_target)
        job_executor = job_info.job_executor
        if iscoroutinefunction(job_func):
            job_executor = 'default'
        scheduler.add_job(
            func=job_func,
            trigger=MyCronTrigger.from_crontab(job_info.cron_expression),
            args=job_info.job_args.split(',') if job_info.job_args else None,
            kwargs=json.loads(job_info.job_kwargs) if job_info.job_kwargs else None,
            id=str(job_info.job_id),
            name=job_info.job_name,
            misfire_grace_time=1000000000000 if job_info.misfire_policy == '3' else None,
            coalesce=job_info.misfire_policy == '2',
            max_instances=3 if job_info.concurrent == '0' else 1,
            jobstore=job_info.job_group,
            executor=job_executor,
        )

    @classmethod
    def execute_scheduler_job_once(cls, job_info: JobModel) -> None:
        """
        æ ¹æ®è¾“å…¥çš„ä»»åŠ¡å¯¹è±¡æ‰§è¡Œä¸€æ¬¡ä»»åŠ¡

        :param job_info: ä»»åŠ¡å¯¹è±¡ä¿¡æ¯
        :return:
        """
        job_func = cls._import_function(job_info.invoke_target)
        job_executor = job_info.job_executor
        if iscoroutinefunction(job_func):
            job_executor = 'default'
        job_trigger = DateTrigger()
        if job_info.status == '0':
            job_trigger = OrTrigger(triggers=[DateTrigger(), MyCronTrigger.from_crontab(job_info.cron_expression)])
        scheduler.add_job(
            func=job_func,
            trigger=job_trigger,
            args=job_info.job_args.split(',') if job_info.job_args else None,
            kwargs=json.loads(job_info.job_kwargs) if job_info.job_kwargs else None,
            id=str(job_info.job_id),
            name=job_info.job_name,
            misfire_grace_time=1000000000000 if job_info.misfire_policy == '3' else None,
            coalesce=job_info.misfire_policy == '2',
            max_instances=3 if job_info.concurrent == '0' else 1,
            jobstore=job_info.job_group,
            executor=job_executor,
        )

    @classmethod
    def remove_scheduler_job(cls, job_id: str | int) -> None:
        """
        æ ¹æ®ä»»åŠ¡idç§»é™¤ä»»åŠ¡

        :param job_id: ä»»åŠ¡id
        :return:
        """
        query_job = cls.get_scheduler_job(job_id=job_id)
        if query_job:
            scheduler.remove_job(job_id=str(job_id))

    @classmethod
    def scheduler_event_listener(cls, event: SchedulerEvent) -> None:
        # è·å–äº‹ä»¶ç±»å‹å’Œä»»åŠ¡ID
        event_type = event.__class__.__name__
        # è·å–ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸ä¿¡æ¯
        status = '0'
        exception_info = ''
        if event_type == 'JobExecutionEvent' and event.exception:
            exception_info = str(event.exception)
            status = '1'
        if hasattr(event, 'job_id'):
            job_id = event.job_id
            query_job = cls.get_scheduler_job(job_id=job_id)
            if query_job:
                try:
                    # å°è¯•è·å–ä»»åŠ¡çŠ¶æ€ä¿¡æ¯
                    query_job_info = query_job.__getstate__()
                    # è·å–ä»»åŠ¡åç§°
                    job_name = query_job_info.get('name')
                    # è·å–ä»»åŠ¡ç»„å
                    job_group = query_job._jobstore_alias
                    # è·å–ä»»åŠ¡æ‰§è¡Œå™¨
                    job_executor = query_job_info.get('executor')
                    # è·å–è°ƒç”¨ç›®æ ‡å­—ç¬¦ä¸²
                    invoke_target = query_job_info.get('func')
                    # è·å–è°ƒç”¨å‡½æ•°ä½ç½®å‚æ•°ï¼ˆargs å¯èƒ½å« int ç­‰ï¼Œéœ€è½¬ä¸º str å† joinï¼‰
                    job_args = ','.join(str(a) for a in query_job_info.get('args', []))
                    # è·å–è°ƒç”¨å‡½æ•°å…³é”®å­—å‚æ•°
                    job_kwargs = json.dumps(query_job_info.get('kwargs', {}))
                    # è·å–ä»»åŠ¡è§¦å‘å™¨
                    job_trigger = str(query_job_info.get('trigger'))
                except (ValueError, AttributeError) as e:
                    # å¦‚æœæ— æ³•åºåˆ—åŒ–ï¼ˆå¦‚ Tushare ä»»åŠ¡çš„é—­åŒ…å‡½æ•°ï¼‰ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
                    logger.debug(f'ä»»åŠ¡ {job_id} æ— æ³•åºåˆ—åŒ–ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ: {e}')
                    # ç›´æ¥ä» job å¯¹è±¡è·å–å±æ€§
                    job_name = query_job.name if hasattr(query_job, 'name') else str(job_id)
                    job_group = query_job._jobstore_alias if hasattr(query_job, '_jobstore_alias') else 'default'
                    job_executor = query_job._executor if hasattr(query_job, '_executor') else 'default'
                    
                    # å¯¹äº Tushare ä»»åŠ¡ï¼Œä½¿ç”¨ç‰¹æ®Šæ ‡è¯†
                    if job_id and job_id.startswith('tushare_task_'):
                        invoke_target = 'module_tushare.task.tushare_download_task.download_tushare_data_sync'
                        # å°è¯•ä» job_id æå– task_id
                        try:
                            task_id = int(job_id.replace('tushare_task_', ''))
                            job_args = str(task_id)
                        except ValueError:
                            # å¦‚æœæ— æ³•ä» job_id æå–ï¼Œå°è¯•ä» job.args è·å–
                            if hasattr(query_job, 'args') and query_job.args:
                                job_args = ','.join(str(arg) for arg in query_job.args)
                            else:
                                job_args = ''
                    else:
                        # å°è¯•è·å–å‡½æ•°å
                        if hasattr(query_job, 'func') and query_job.func:
                            func = query_job.func
                            if hasattr(func, '__module__') and hasattr(func, '__name__'):
                                invoke_target = f'{func.__module__}.{func.__name__}'
                            else:
                                invoke_target = str(func)
                        else:
                            invoke_target = 'unknown'
                        # è·å–å‚æ•°
                        if hasattr(query_job, 'args') and query_job.args:
                            job_args = ','.join(str(arg) for arg in query_job.args)
                        else:
                            job_args = ''
                    
                    # è·å–å…³é”®å­—å‚æ•°
                    job_kwargs = json.dumps(query_job.kwargs) if hasattr(query_job, 'kwargs') and query_job.kwargs else '{}'
                    # è·å–ä»»åŠ¡è§¦å‘å™¨
                    job_trigger = str(query_job.trigger) if hasattr(query_job, 'trigger') else 'unknown'
                
                # æ„é€ æ—¥å¿—æ¶ˆæ¯
                job_message = f'äº‹ä»¶ç±»å‹: {event_type}, ä»»åŠ¡ID: {job_id}, ä»»åŠ¡åç§°: {job_name}, æ‰§è¡Œäº{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}'
                job_log = JobLogModel(
                    jobName=job_name,
                    jobGroup=job_group,
                    jobExecutor=job_executor,
                    invokeTarget=invoke_target,
                    jobArgs=job_args,
                    jobKwargs=job_kwargs,
                    jobTrigger=job_trigger,
                    jobMessage=job_message,
                    status=status,
                    exceptionInfo=exception_info,
                    createTime=datetime.now(),
                )
                session = SessionLocal()
                JobLogService.add_job_log_services(session, job_log)
                session.close()
